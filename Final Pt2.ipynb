{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de Final Pt2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwpsXZGrXTpO"
      },
      "source": [
        "# 2. (15 points) Use Keras to load one of the deep CNN models trained on the **ILSVRC-2012-CLS** image classification dataset (ImageNet). See below to find out which model to load:\r\n",
        "> If your last name starts with A, B: InceptionResNetV2.\r\n",
        "If your last name starts with C, D, E, F, G, H: ResNet50-V2.\r\n",
        "If your last name starts with I, J, K, L, M: VGG16.\r\n",
        "If your last name starts with N, O, P, Q: MobileNet-v2.\r\n",
        "If your last name starts with R, S: InceptionV3.\r\n",
        "If your last name starts with T, U, V, W, X, Y, Z: VGG19.\r\n",
        "\r\n",
        "(Note: if you load the wrong network, you wonâ€™t get any points!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-uPlCu6cdCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "557fc5c4-6772-4055-9252-6c8631edd4c2"
      },
      "source": [
        "\"\"\"Last name: Asqiriba -> InceptionResNetV2\r\n",
        "\r\n",
        "Keras class parameters:\r\n",
        "  tf.keras.applications.InceptionResNetV2(\r\n",
        "    include_top=True,\r\n",
        "    weights=\"imagenet\",\r\n",
        "    input_tensor=None,\r\n",
        "    input_shape=None,\r\n",
        "    pooling=None,\r\n",
        "    classes=1000,\r\n",
        "    classifier_activation=\"softmax\",\r\n",
        "    **kwargs\r\n",
        "  )\r\n",
        "\r\n",
        "Atributes:\r\n",
        "  IMG_SIZE   = 299x299\r\n",
        "  Weights    = 215MB\r\n",
        "  Top1A      = 0.804\r\n",
        "  Top5A      = 0.953\r\n",
        "  Parameters = 55,873,736\r\n",
        "  Depth      = 572\r\n",
        "  Accuracy   = 0.843\r\n",
        "  F1 score   = 0.833\r\n",
        "\r\n",
        "Keras implementation site:\r\n",
        "  https://keras.io/api/applications/inceptionresnetv2/\r\n",
        "\r\n",
        "InceptionResNetV2 site:\r\n",
        "  https://arxiv.org/abs/1602.07261\r\n",
        "\"\"\"\r\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2, decode_predictions, preprocess_input\r\n",
        "\r\n",
        "# Image dictionary stored in my Colab instance.\r\n",
        "IMG_BANK = {\r\n",
        "    'Lion' : '/content/download (1).jpeg',\r\n",
        "    'Bike' : '/content/download (2).jpeg',\r\n",
        "    'Coffee' : '/content/download (5).jpeg',\r\n",
        "    'Kite' : '/content/download (6).jpeg',\r\n",
        "    'Snail' : '/content/download (7).jpeg',\r\n",
        "    'Bench' : '/content/download (8).jpeg',\r\n",
        "    'Leopard' : '/content/download.jpeg',\r\n",
        "    'Cat' : '/content/image.jpeg',\r\n",
        "    'Bus' : '/content/images (1).jpeg',\r\n",
        "    'Pig' : '/content/img.png'\r\n",
        "}\r\n",
        "\r\n",
        "# We store the features(mean) of the images for part C.\r\n",
        "IMG_FEATURES = {\r\n",
        "    'Lion' : 0,\r\n",
        "    'Bike' : 0,\r\n",
        "    'Coffee' : 0,\r\n",
        "    'Kite' : 0,\r\n",
        "    'Snail' : 0,\r\n",
        "    'Bench' : 0,\r\n",
        "    'Leopard' : 0,\r\n",
        "    'Cat' : 0,\r\n",
        "    'Bus' : 0,\r\n",
        "    'Pig' : 0\r\n",
        "}\r\n",
        "\r\n",
        "# Init the model.\r\n",
        "model = InceptionResNetV2(weights=\"imagenet\")\r\n",
        "print('Model: InceptionResNetV2')"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: InceptionResNetV2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gXoUZekY2as"
      },
      "source": [
        "## (a) Evaluate the performance of the selected model using the given test set available under Week 13 module (img.zip folder includes 10 images), and calculate the top1-accuracy and top5-accuracy for that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfIU2LP8CvvV"
      },
      "source": [
        "from keras.preprocessing.image import load_img, img_to_array\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "# Retrieve an image from the files.\r\n",
        "IMG_PATH = IMG_BANK['Lion']\r\n",
        "\r\n",
        "# Save the name of selected image for dict handling.\r\n",
        "name_image = list(IMG_BANK.keys())[list(IMG_BANK.values()).index(IMG_PATH)]\r\n",
        "\r\n",
        "# Load image, resize acording to the model's needs.\r\n",
        "img = load_img(IMG_PATH, target_size=(299, 299))\r\n",
        "\r\n",
        "# Convert img to arr(h, w, channel), then into batch(batch, h, w, ch).\r\n",
        "processed_image = img_to_array(img)\r\n",
        "batch_image = np.expand_dims(processed_image, axis=0)\r\n",
        "digested_image = preprocess_input(batch_image)\r\n",
        "\r\n",
        "# Digest image into the model and decode it; make it human-readable.\r\n",
        "predictions = model.predict(digested_image)"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrejFSKkT6MC",
        "outputId": "67a22cd9-2033-497f-996b-cfe11218d7ed"
      },
      "source": [
        "# We take the TopK from the model, then print it.\r\n",
        "top1_labels = decode_predictions(predictions, top=1)\r\n",
        "top5_labels = decode_predictions(predictions)\r\n",
        "\r\n",
        "# Brief explanation of what TopX accuracy means.\r\n",
        "print('\\nInceptionResNetV2 TopK scores:\\n'\r\n",
        "    + '\\nTop-1 accuracy is the conventional accuracy, which means that the model '\r\n",
        "    + 'answer \\n(the one with the highest probability) must be exactly the expected answer.'\r\n",
        "    +f'\\n\\n{top1_labels[0][0]}\\n'\r\n",
        "    + '\\n\\nTop-5 accuracy means that any of your model that gives 5 highest probability\\n answers'\r\n",
        "    + ' that must match the expected answer.\\n'\r\n",
        "    )\r\n",
        "\r\n",
        "for i in range(len(top5_labels[0])):\r\n",
        "  print(top5_labels[0][i])"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "InceptionResNetV2 TopK scores:\n",
            "\n",
            "Top-1 accuracy is the conventional accuracy, which means that the model answer \n",
            "(the one with the highest probability) must be exactly the expected answer.\n",
            "\n",
            "('n02129165', 'lion', 0.9288668)\n",
            "\n",
            "\n",
            "Top-5 accuracy means that any of your model that gives 5 highest probability\n",
            " answers that must match the expected answer.\n",
            "\n",
            "('n02129165', 'lion', 0.9288668)\n",
            "('n02125311', 'cougar', 0.00089567434)\n",
            "('n02129604', 'tiger', 0.0007001101)\n",
            "('n02130308', 'cheetah', 0.0003819853)\n",
            "('n02106030', 'collie', 0.00034011155)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDpJOK2v9mRM"
      },
      "source": [
        "Historical outputs:\r\n",
        "---\r\n",
        "\r\n",
        "Image 1: Lion.\r\n",
        "```\r\n",
        "> ('n02129165', 'lion', 0.9288668)\r\n",
        "('n02125311', 'cougar', 0.00089567434)\r\n",
        "('n02129604', 'tiger', 0.0007001101)\r\n",
        "('n02130308', 'cheetah', 0.0003819853)\r\n",
        "('n02106030', 'collie', 0.00034011155)\r\n",
        "```\r\n",
        "---\r\n",
        "\r\n",
        "Image 2: Bike.\r\n",
        "```\r\n",
        "> ('n03792782', 'mountain_bike', 0.6611452)**\r\n",
        "('n02835271', 'bicycle-built-for-two', 0.053169418)\r\n",
        "('n04482393', 'tricycle', 0.008381028)\r\n",
        "('n04235860', 'sleeping_bag', 0.0054462613)\r\n",
        "('n03764736', 'milk_can', 0.0039183004)\r\n",
        "```\r\n",
        "---\r\n",
        "\r\n",
        "Image 3: Coffee.\r\n",
        "```\r\n",
        "> ('n07930864', 'cup', 0.5445497)\r\n",
        "('n07920052', 'espresso', 0.1077343)\r\n",
        "('n03063599', 'coffee_mug', 0.095277004)\r\n",
        "('n07932039', 'eggnog', 0.021933636)\r\n",
        "('n03297495', 'espresso_maker', 0.021787835)\r\n",
        "```\r\n",
        "---\r\n",
        "\r\n",
        "Image 4: Kite.\r\n",
        "```\r\n",
        "> ('n03355925', 'flagpole', 0.46088904)\r\n",
        "('n03888257', 'parachute', 0.40852448)\r\n",
        "('n03733131', 'maypole', 0.021915112)\r\n",
        "('n03976657', 'pole', 0.006420887)\r\n",
        "('n03944341', 'pinwheel', 0.004615334)\r\n",
        "```\r\n",
        "---\r\n",
        "\r\n",
        "Image 5: Snail.\r\n",
        "```\r\n",
        "> ('n01944390', 'snail', 0.9255499)\r\n",
        "('n01945685', 'slug', 0.002956227)\r\n",
        "('n01943899', 'conch', 0.0021765176)\r\n",
        "('n01986214', 'hermit_crab', 0.0005132853)\r\n",
        "('n01968897', 'chambered_nautilus', 0.0004910154)\r\n",
        "```\r\n",
        "---\r\n",
        "\r\n",
        "Image 6: Bench.\r\n",
        "```\r\n",
        "('n03891251', 'park_bench', 0.94239813)\r\n",
        "('n02747177', 'ashcan', 0.0023240522)\r\n",
        "('n02892201', 'brass', 0.0006186887)\r\n",
        "('n09332890', 'lakeside', 0.00044254796)\r\n",
        "('n03991062', 'pot', 0.00028989476)\r\n",
        "```\r\n",
        "---\r\n",
        "\r\n",
        "Image 7: Leopard.\r\n",
        "```\r\n",
        "> ('n02128385', 'leopard', 0.92392915)\r\n",
        "('n02128925', 'jaguar', 0.010171026)\r\n",
        "('n02130308', 'cheetah', 0.0016932078)\r\n",
        "('n02128757', 'snow_leopard', 0.0015446297)\r\n",
        "('n02606052', 'rock_beauty', 0.0009375865)\r\n",
        "```\r\n",
        "---\r\n",
        "\r\n",
        "Image 8: Cat.\r\n",
        "```\r\n",
        "> ('n02123394', 'Persian_cat', 0.8734948)\r\n",
        "('n02127052', 'lynx', 0.006491119)\r\n",
        "('n02328150', 'Angora', 0.004858171)\r\n",
        "('n02123045', 'tabby', 0.0020751117)\r\n",
        "('n03721384', 'marimba', 0.0013176007)\r\n",
        "```\r\n",
        "---\r\n",
        "\r\n",
        "Image 9: Bus.\r\n",
        "```\r\n",
        "> ('n03769881', 'minibus', 0.7118722)\r\n",
        "('n03977966', 'police_van', 0.12225373)\r\n",
        "('n02701002', 'ambulance', 0.039510496)\r\n",
        "('n03796401', 'moving_van', 0.009279929)\r\n",
        "('n03770679', 'minivan', 0.0051392214)\r\n",
        "```\r\n",
        "---\r\n",
        "\r\n",
        "Image 10: Hog.\r\n",
        "```\r\n",
        "> ('n02395406', 'hog', 0.87603027)\r\n",
        "('n02396427', 'wild_boar', 0.041023444)\r\n",
        "('n03935335', 'piggy_bank', 0.004426862)\r\n",
        "('n02927161', 'butcher_shop', 0.0006680207)\r\n",
        "('n02364673', 'guinea_pig', 0.000499933)\r\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN_jGTwLZAkT"
      },
      "source": [
        "## (b) Use the loaded model to extract the features from each image. Print out the features and the shape of the extracted features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V7p6znlJeIS",
        "outputId": "41300b3b-a154-4bdd-ab58-32c5e18c848e"
      },
      "source": [
        "# Using a pre-trained model in Keras to extract the feature of a given image.\r\n",
        "print(f'Image Size of {name_image}: {img.size}')\r\n",
        "print(f'Shape of feature extraction: {predictions.shape}\\n')\r\n",
        "print(f'Features:\\n{predictions}')\r\n",
        "\r\n",
        "# Write the mean value of the prediction into the dictionary.\r\n",
        "IMG_FEATURES[name_image] = np.ndarray.mean(predictions)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image Size of Lion: (299, 299)\n",
            "Shape of feature extraction: (1, 1000)\n",
            "\n",
            "Features:\n",
            "[[9.23769476e-05 3.68620276e-05 8.26739924e-05 9.06900605e-05\n",
            "  8.31967118e-05 9.40543905e-05 6.55475524e-05 3.25924848e-05\n",
            "  3.56815253e-05 4.95785025e-05 5.01965078e-05 5.58681022e-05\n",
            "  6.83282196e-05 5.34160245e-05 6.08459632e-05 5.71265191e-05\n",
            "  5.22573282e-05 9.03378605e-05 5.82618559e-05 4.46375707e-05\n",
            "  4.72383035e-05 8.28952907e-05 1.07261789e-04 1.05099018e-04\n",
            "  5.32631129e-05 7.30510947e-05 1.12237030e-04 9.23615298e-05\n",
            "  9.02874817e-05 6.96787247e-05 4.61813142e-05 6.14220407e-05\n",
            "  5.83556648e-05 1.26055558e-04 3.97085205e-05 5.74567493e-05\n",
            "  3.53912255e-05 5.26814038e-05 7.75277585e-05 5.26917029e-05\n",
            "  4.24106620e-05 4.30030086e-05 5.66425697e-05 6.13887751e-05\n",
            "  3.00643715e-05 5.75831909e-05 2.91735905e-05 5.97929902e-05\n",
            "  7.06835272e-05 5.12992410e-05 3.58791331e-05 4.49288855e-05\n",
            "  8.91584423e-05 1.04386600e-04 4.73237051e-05 5.19354326e-05\n",
            "  4.87063517e-05 6.61470112e-05 8.42912414e-05 4.88402184e-05\n",
            "  6.12338918e-05 4.32777924e-05 6.17025580e-05 5.06167489e-05\n",
            "  6.33919117e-05 7.56696681e-05 4.35063012e-05 9.62427803e-05\n",
            "  7.46759761e-05 4.36230912e-05 6.58450954e-05 7.02027246e-05\n",
            "  6.98999575e-05 7.28779705e-05 7.58399474e-05 5.85333000e-05\n",
            "  4.86601530e-05 5.16108921e-05 3.32074051e-05 6.33895615e-05\n",
            "  7.19504460e-05 6.89337030e-05 3.83617480e-05 1.10378154e-04\n",
            "  4.07657171e-05 4.73714317e-05 6.72735696e-05 4.87480320e-05\n",
            "  7.04000340e-05 7.03737169e-05 5.03107658e-05 3.73984476e-05\n",
            "  8.30874560e-05 1.58293929e-04 3.68416077e-05 7.22356999e-05\n",
            "  4.06654544e-05 6.54435571e-05 8.61483932e-05 2.90295757e-05\n",
            "  3.89823617e-05 6.86682979e-05 3.84910345e-05 6.05766763e-05\n",
            "  8.94301847e-05 1.11081557e-04 4.56798225e-05 5.23962553e-05\n",
            "  7.11043322e-05 5.13119121e-05 6.12034710e-05 6.93117618e-05\n",
            "  3.79564626e-05 3.75549898e-05 3.75585405e-05 1.09584696e-04\n",
            "  9.61151018e-05 6.76543204e-05 3.99580604e-05 1.02011967e-04\n",
            "  6.12774675e-05 4.94409142e-05 4.44639663e-05 3.86037100e-05\n",
            "  4.12929257e-05 5.23318849e-05 6.80680605e-05 5.02603143e-05\n",
            "  6.24250679e-05 6.45304754e-05 6.31497096e-05 6.02928230e-05\n",
            "  6.20473438e-05 6.66130654e-05 4.32183188e-05 4.31623812e-05\n",
            "  3.64674743e-05 4.21068326e-05 7.27692823e-05 4.77769026e-05\n",
            "  3.22673150e-05 4.09784952e-05 3.78533659e-05 3.21963416e-05\n",
            "  3.60958620e-05 5.12638326e-05 5.00369715e-05 4.98578702e-05\n",
            "  8.49454591e-05 5.36989355e-05 1.45554732e-04 3.97940057e-05\n",
            "  9.59825629e-05 3.80409692e-05 9.24599735e-05 7.80084156e-05\n",
            "  1.44278572e-04 4.46908562e-05 4.47259008e-05 7.26689323e-05\n",
            "  3.45032749e-05 6.52006711e-05 3.39342550e-05 7.61306728e-05\n",
            "  8.39111599e-05 6.20429637e-05 1.29088585e-04 5.56412160e-05\n",
            "  4.02986152e-05 3.40944353e-05 7.39050083e-05 4.46239501e-05\n",
            "  6.31353250e-05 7.37577793e-05 3.73392904e-05 1.33055408e-04\n",
            "  9.06248679e-05 4.25540020e-05 6.94264018e-05 5.59439686e-05\n",
            "  8.87959395e-05 2.72418838e-05 4.27083323e-05 2.75939856e-05\n",
            "  4.43253120e-05 1.96071807e-04 1.44758887e-04 1.32383953e-04\n",
            "  6.12216827e-05 8.36380786e-05 4.77034191e-05 9.45187348e-05\n",
            "  4.76939131e-05 1.71816268e-04 5.50852528e-05 5.76116436e-05\n",
            "  7.23564954e-05 2.71977551e-05 3.84033337e-05 3.54482108e-05\n",
            "  1.49176660e-04 6.08646515e-05 4.40994372e-05 5.95885685e-05\n",
            "  1.48875784e-04 5.34754545e-05 6.73989853e-05 1.19319244e-04\n",
            "  3.36197991e-05 3.81196332e-05 2.18430705e-05 1.02257909e-04\n",
            "  2.81348202e-05 6.02291511e-05 6.34830867e-05 4.81722018e-05\n",
            "  6.12757140e-05 3.16470105e-05 5.70647753e-05 5.06962642e-05\n",
            "  1.77099631e-04 5.33919847e-05 8.95227713e-05 1.07364895e-05\n",
            "  2.64369126e-04 2.76051469e-05 1.15518662e-04 5.94488811e-05\n",
            "  8.34707389e-05 6.52524250e-05 2.45421223e-04 3.40111554e-04\n",
            "  9.45129650e-05 4.90545244e-05 4.92059116e-05 1.30161483e-04\n",
            "  6.81545134e-05 3.59597325e-05 2.81048397e-05 5.20077920e-05\n",
            "  5.31025871e-05 9.56521399e-05 4.69317019e-05 1.51726417e-04\n",
            "  2.60061555e-04 3.34110191e-05 7.79408219e-05 4.93243060e-05\n",
            "  5.78081781e-05 3.45047883e-05 2.94735419e-05 3.44147775e-05\n",
            "  6.91965106e-05 7.85109296e-05 5.93689438e-05 2.43283372e-04\n",
            "  1.42407967e-04 4.76345485e-05 1.08875822e-04 1.51990287e-04\n",
            "  3.21745785e-04 2.46075302e-04 4.68378021e-05 1.31590759e-05\n",
            "  2.58604468e-05 3.93287810e-05 5.40688234e-05 6.20003775e-05\n",
            "  5.64916263e-05 9.71115660e-05 1.33126101e-04 8.97333011e-05\n",
            "  7.64634169e-05 1.73247434e-04 2.12536994e-04 7.87759782e-05\n",
            "  2.44805240e-04 3.28454480e-05 3.88534245e-05 6.21921354e-05\n",
            "  4.35116563e-05 6.66089327e-05 1.00790130e-04 1.97685586e-04\n",
            "  3.86862666e-05 5.85293892e-05 8.95674340e-04 2.10634593e-04\n",
            "  2.80533306e-04 2.10589002e-04 2.47425574e-04 9.28866804e-01\n",
            "  7.00110104e-04 3.81985301e-04 1.65139252e-04 3.18991151e-05\n",
            "  1.09380257e-04 9.86257073e-05 3.25109031e-05 2.64553855e-05\n",
            "  5.62867899e-05 4.36141854e-05 7.38575909e-05 3.29501418e-05\n",
            "  4.92420550e-05 8.69492724e-05 7.31652253e-05 5.51174126e-05\n",
            "  8.85007248e-05 5.99300656e-05 3.34683609e-05 4.84278426e-05\n",
            "  5.05201533e-05 4.89089216e-05 4.39685828e-05 4.83116928e-05\n",
            "  5.31498554e-05 7.99242407e-05 2.83351019e-05 7.33833949e-05\n",
            "  8.69891664e-05 3.79558114e-05 5.07604636e-05 5.71390046e-05\n",
            "  6.30446448e-05 8.15564272e-05 6.89118751e-05 5.09788697e-05\n",
            "  6.94160772e-05 6.43982348e-05 1.41324454e-05 1.44735823e-04\n",
            "  3.56128221e-05 1.90532282e-05 5.29398712e-05 5.25694340e-05\n",
            "  5.97166909e-05 7.78201284e-05 3.89527049e-05 9.50397371e-05\n",
            "  1.93547399e-04 5.16652108e-05 4.89268314e-05 4.29322390e-05\n",
            "  1.11847767e-04 2.75975268e-04 6.72563110e-05 1.26298764e-04\n",
            "  1.55651025e-04 8.64869726e-05 6.96581919e-05 1.11856949e-04\n",
            "  1.42871009e-04 5.95113961e-05 1.98618160e-04 5.30795005e-05\n",
            "  2.92674449e-05 2.84171001e-05 5.10235695e-05 3.41029590e-05\n",
            "  8.61838198e-05 3.04599525e-05 3.73082876e-05 8.53023303e-05\n",
            "  4.32653687e-05 1.40187156e-04 2.75071761e-05 9.57334487e-05\n",
            "  1.01705104e-04 4.57018286e-05 6.61964878e-05 1.14759248e-04\n",
            "  1.03994113e-04 2.74726626e-04 1.80370567e-04 4.89265076e-05\n",
            "  5.04974632e-05 4.84983284e-05 9.11693351e-05 4.33657915e-05\n",
            "  4.69128136e-05 4.02465012e-05 3.58776597e-05 4.25682083e-05\n",
            "  3.15062316e-05 9.36059078e-05 5.93650911e-05 5.81376917e-05\n",
            "  8.91345553e-05 4.43860117e-05 4.54084038e-05 6.67648128e-05\n",
            "  6.63006722e-05 6.25536777e-05 5.36184925e-05 3.40118204e-05\n",
            "  8.06769385e-05 4.98452209e-05 7.03652622e-05 4.14674687e-05\n",
            "  4.38171373e-05 7.80830014e-05 7.26700382e-05 1.51932312e-04\n",
            "  4.00996505e-05 7.51716434e-05 6.07994989e-05 9.05185370e-05\n",
            "  2.01196250e-04 5.64166294e-05 9.17253055e-05 9.90423141e-05\n",
            "  3.93558657e-05 5.51760495e-05 5.63027861e-05 7.27439547e-05\n",
            "  7.74995860e-05 8.05202944e-05 8.55558683e-05 4.00148820e-05\n",
            "  8.14406230e-05 4.43026183e-05 6.08706905e-05 5.10221071e-05\n",
            "  6.57138589e-05 1.07796470e-04 4.78955153e-05 8.92374737e-05\n",
            "  5.97840444e-05 4.52854110e-05 5.21815782e-05 7.29445819e-05\n",
            "  9.00855302e-05 4.36723749e-05 5.96983555e-05 6.96301649e-05\n",
            "  8.42225418e-05 6.28843190e-05 4.02414335e-05 8.59046559e-05\n",
            "  5.68273936e-05 3.51380877e-05 4.31103836e-05 1.66455720e-04\n",
            "  5.26971780e-05 5.43762944e-05 2.52637510e-05 3.66587992e-05\n",
            "  3.60369086e-05 9.00904270e-05 5.15984902e-05 5.18479828e-05\n",
            "  5.99978848e-05 4.42201781e-05 3.68342335e-05 6.01561333e-05\n",
            "  7.67228048e-05 8.29033524e-05 4.34979229e-05 9.71902264e-05\n",
            "  5.15273823e-05 4.71351159e-05 8.45425820e-05 4.43796634e-05\n",
            "  4.68807484e-05 5.29820427e-05 5.36042280e-05 7.25715581e-05\n",
            "  4.09632194e-05 4.06399449e-05 4.26016304e-05 2.95474183e-05\n",
            "  5.05983116e-05 5.51767371e-05 5.48494609e-05 5.38082786e-05\n",
            "  5.35677900e-05 7.32330809e-05 1.08861801e-04 8.94341065e-05\n",
            "  6.53609750e-05 4.52439708e-05 6.86017302e-05 5.53771097e-05\n",
            "  4.58510003e-05 6.82692698e-05 6.38111014e-05 6.87378124e-05\n",
            "  9.43983832e-05 7.08315783e-05 6.48273563e-05 9.04455374e-05\n",
            "  5.64621623e-05 9.05540219e-05 7.46997684e-05 6.42047671e-05\n",
            "  5.07220429e-05 5.78620165e-05 5.87402028e-05 7.06250430e-05\n",
            "  4.25555008e-05 5.93569384e-05 1.42392062e-04 4.79632545e-05\n",
            "  8.32528385e-05 5.96458267e-05 2.70214587e-05 6.26134715e-05\n",
            "  8.15811654e-05 4.59124349e-05 1.42372519e-04 1.04092047e-04\n",
            "  1.23150763e-04 4.78270013e-05 3.54620424e-05 5.65339360e-05\n",
            "  5.54967555e-05 8.52111043e-05 5.88978837e-05 3.71014321e-05\n",
            "  7.35633294e-05 9.22411127e-05 3.93676892e-05 5.75647427e-05\n",
            "  4.82189425e-05 7.93586296e-05 1.34813323e-04 1.00487327e-04\n",
            "  1.09950866e-04 8.31545112e-05 9.47778826e-05 1.94627821e-04\n",
            "  3.90044515e-05 6.47823617e-05 6.23086089e-05 4.75167180e-05\n",
            "  7.45149882e-05 5.66839080e-05 8.94671175e-05 8.67785420e-05\n",
            "  8.83506218e-05 6.40134022e-05 3.99326163e-05 5.60012995e-05\n",
            "  7.10717213e-05 6.47419074e-05 5.94793346e-05 7.52215637e-05\n",
            "  9.69458415e-05 6.68015637e-05 1.12471367e-04 5.82716893e-05\n",
            "  4.69975857e-05 7.74935979e-05 4.13247581e-05 1.08077897e-04\n",
            "  6.05869609e-05 6.54454270e-05 1.21058016e-04 5.12472143e-05\n",
            "  5.47122727e-05 7.21248070e-05 4.53597568e-05 4.32181114e-05\n",
            "  7.59569884e-05 6.21965228e-05 4.93221414e-05 9.98646283e-05\n",
            "  5.54651633e-05 7.23024859e-05 5.59532527e-05 5.27030097e-05\n",
            "  5.81288768e-05 8.55961844e-05 5.28091150e-05 5.80720261e-05\n",
            "  6.64207255e-05 5.75425656e-05 3.75476520e-05 4.40832919e-05\n",
            "  3.36091907e-05 6.67734057e-05 1.01220226e-04 4.69840961e-05\n",
            "  1.23937571e-04 8.35505416e-05 8.77837956e-05 3.90571186e-05\n",
            "  4.31504850e-05 5.95450074e-05 1.37358540e-04 5.16535365e-05\n",
            "  6.49022622e-05 8.44529786e-05 6.82661412e-05 5.49824872e-05\n",
            "  4.65188023e-05 6.21759391e-05 5.14404783e-05 9.42174229e-05\n",
            "  5.14914245e-05 9.05645575e-05 6.83560502e-05 3.40832230e-05\n",
            "  1.59035961e-04 3.70169619e-05 4.33820096e-05 1.00463847e-04\n",
            "  5.38768290e-05 1.09891960e-04 3.39386243e-05 5.00364004e-05\n",
            "  5.76535276e-05 1.22535828e-04 4.60891861e-05 6.00609746e-05\n",
            "  6.44706888e-05 7.41094773e-05 9.29428497e-05 7.33603665e-05\n",
            "  3.83347942e-05 5.62242894e-05 8.56720580e-05 8.66831688e-05\n",
            "  6.14196324e-05 4.22818339e-05 3.28471069e-05 5.70237607e-05\n",
            "  7.34655332e-05 6.29021888e-05 1.04394858e-04 3.98487282e-05\n",
            "  5.05613134e-05 9.09787777e-05 5.60869739e-05 5.46393785e-05\n",
            "  5.60593799e-05 7.15235437e-05 5.82878092e-05 1.10152592e-04\n",
            "  6.78733340e-05 7.42520278e-05 6.06055655e-05 7.49199389e-05\n",
            "  4.85981000e-05 7.56843947e-05 7.33218330e-05 6.37754492e-05\n",
            "  8.43928356e-05 5.50664518e-05 5.27186421e-05 6.53720126e-05\n",
            "  3.45078151e-05 6.94257396e-05 6.48512869e-05 8.78288411e-05\n",
            "  6.68783032e-05 7.19326708e-05 3.92047914e-05 7.37670634e-05\n",
            "  1.09537672e-04 7.42979246e-05 8.01066926e-05 6.26042238e-05\n",
            "  6.85081031e-05 7.66775265e-05 6.88704895e-05 3.94204399e-05\n",
            "  7.17848525e-05 7.73942666e-05 8.26390678e-05 3.99635901e-05\n",
            "  8.10735364e-05 7.52940468e-05 3.61139064e-05 7.66010708e-05\n",
            "  1.51807020e-04 6.68149369e-05 3.26480309e-04 7.54529028e-05\n",
            "  4.40887998e-05 9.46498039e-05 8.76841368e-05 6.97499345e-05\n",
            "  4.22785270e-05 9.35001881e-05 9.78875978e-05 6.86293424e-05\n",
            "  6.04054585e-05 5.81299864e-05 6.82862592e-05 4.09214445e-05\n",
            "  8.74797552e-05 8.42702648e-05 3.04806435e-05 5.84203699e-05\n",
            "  2.71273202e-05 6.08276277e-05 7.09726301e-05 1.03545026e-04\n",
            "  7.06317733e-05 5.40140900e-05 5.23884082e-05 4.73215368e-05\n",
            "  3.79291414e-05 7.23107660e-05 4.93391744e-05 4.88831793e-05\n",
            "  3.25247311e-05 4.82106661e-05 3.28308233e-05 5.59987348e-05\n",
            "  3.62134051e-05 8.73969475e-05 5.00641800e-05 9.31145260e-05\n",
            "  5.58547290e-05 5.29982171e-05 9.11951647e-05 2.46688924e-05\n",
            "  1.22860656e-04 6.32338997e-05 7.93692234e-05 4.29901702e-05\n",
            "  3.55696102e-05 6.46462140e-05 9.02104512e-05 4.52842869e-05\n",
            "  5.64066722e-05 5.98032566e-05 5.18406159e-05 4.75449087e-05\n",
            "  4.73443324e-05 6.38769197e-05 6.92843241e-05 7.51092302e-05\n",
            "  6.46536791e-05 4.67347782e-05 4.03694721e-05 7.99147892e-05\n",
            "  3.70511880e-05 6.12362783e-05 3.70235648e-05 4.66701531e-05\n",
            "  4.57183924e-05 5.61075722e-05 5.12050028e-05 4.17252413e-05\n",
            "  4.06986655e-05 8.80614170e-05 6.10240204e-05 4.20548240e-05\n",
            "  9.45288339e-05 3.88179069e-05 6.95281778e-05 7.23383491e-05\n",
            "  3.46632005e-05 9.20793973e-05 3.81663376e-05 4.89034610e-05\n",
            "  7.09536107e-05 1.02927719e-04 4.56891903e-05 6.50352886e-05\n",
            "  5.06107135e-05 3.97342010e-05 5.02374060e-05 3.51634953e-05\n",
            "  7.54195280e-05 4.23575875e-05 7.82077550e-05 6.48047935e-05\n",
            "  9.41778999e-05 5.61550005e-05 9.84472572e-05 5.57286803e-05\n",
            "  7.01415556e-05 6.37634657e-05 5.31647638e-05 7.14796988e-05\n",
            "  5.46181218e-05 6.28725102e-05 9.86046362e-05 4.15144787e-05\n",
            "  7.44958088e-05 9.01511958e-05 3.83748120e-05 6.85171181e-05\n",
            "  5.24373427e-05 6.72170718e-05 4.52724962e-05 3.74430929e-05\n",
            "  4.85449273e-05 4.23652236e-05 5.42035705e-05 5.81225577e-05\n",
            "  4.73087202e-05 8.91332820e-05 7.57029411e-05 6.33154268e-05\n",
            "  9.00522937e-05 6.96331554e-05 6.31211078e-05 4.60497286e-05\n",
            "  4.16210787e-05 4.78768816e-05 3.91200447e-05 4.11651781e-05\n",
            "  6.34180906e-05 5.70717966e-05 3.28934257e-04 2.18909099e-05\n",
            "  3.66157910e-05 6.66289488e-05 9.83554783e-05 6.59714933e-05\n",
            "  5.07557234e-05 8.99896186e-05 5.68436008e-05 1.02558617e-04\n",
            "  5.13726300e-05 6.64219915e-05 6.64847321e-05 1.65269230e-04\n",
            "  2.40788759e-05 6.68525390e-05 1.64250261e-04 3.32657546e-05\n",
            "  7.13730915e-05 4.59228977e-05 6.77895587e-05 1.05331404e-04\n",
            "  5.82282482e-05 6.74299736e-05 6.90637899e-05 4.83017866e-05\n",
            "  4.32921152e-05 5.53498685e-05 8.87971328e-05 5.10497048e-05\n",
            "  7.66265002e-05 7.76434754e-05 4.39322866e-05 5.58410393e-05\n",
            "  5.22474584e-05 7.67269739e-05 4.19520366e-05 7.03674159e-05\n",
            "  5.31824589e-05 4.90805869e-05 5.20822432e-05 6.51897863e-05\n",
            "  7.49287938e-05 5.52180572e-05 9.97307143e-05 5.01974209e-05\n",
            "  5.50707009e-05 4.14350179e-05 6.22098087e-05 3.81368300e-05\n",
            "  4.63534889e-05 5.26608565e-05 4.39809992e-05 4.00278586e-05\n",
            "  1.35064649e-04 6.81627062e-05 5.00828028e-05 5.42523921e-05\n",
            "  1.03814062e-04 5.35531290e-05 5.37909364e-05 7.16736249e-05\n",
            "  5.30032667e-05 8.41793444e-05 5.52564088e-05 5.27628545e-05\n",
            "  9.00263549e-05 3.98819939e-05 2.43523609e-04 6.58586578e-05\n",
            "  7.35229332e-05 8.73943645e-05 5.21151887e-05 3.96178111e-05\n",
            "  7.17867733e-05 7.44615681e-05 5.22373957e-05 4.56190901e-05\n",
            "  9.94782313e-05 4.94059386e-05 3.95548050e-05 1.33495691e-04\n",
            "  1.22079757e-04 3.84801751e-05 1.20158787e-04 5.27386037e-05\n",
            "  6.27132758e-05 6.19842394e-05 3.68872461e-05 5.42760426e-05\n",
            "  4.92939289e-05 7.41971016e-05 4.90016901e-05 6.70323789e-05\n",
            "  6.68669600e-05 6.23764499e-05 6.50589209e-05 5.09475685e-05\n",
            "  5.19777968e-05 6.47600027e-05 8.85272311e-05 6.36073237e-05\n",
            "  1.08844775e-04 6.95796480e-05 3.15724319e-05 8.30265417e-05\n",
            "  4.52559652e-05 4.34545109e-05 1.20165205e-04 6.72400856e-05\n",
            "  5.34778519e-05 1.00614663e-04 9.72381604e-05 5.40359870e-05\n",
            "  7.76496236e-05 4.98771769e-05 9.06316927e-05 4.47123421e-05\n",
            "  6.87633801e-05 4.57237111e-05 4.93192238e-05 5.20275389e-05\n",
            "  1.02162769e-04 6.54550458e-05 1.01663980e-04 5.03657793e-05\n",
            "  4.54666006e-05 5.10267309e-05 5.04941418e-05 6.86051280e-05\n",
            "  8.47363117e-05 7.29823005e-05 6.04682828e-05 4.58328577e-05\n",
            "  5.69256263e-05 3.44212422e-05 6.04624584e-05 8.55544786e-05\n",
            "  7.25255450e-05 4.33313144e-05 6.55564363e-05 6.54535470e-05\n",
            "  5.02364528e-05 2.88094070e-05 5.05806565e-05 5.70882876e-05\n",
            "  1.52368331e-04 4.04571911e-05 5.03641022e-05 6.68480207e-05\n",
            "  1.05370986e-04 6.94442133e-05 5.13247360e-05 9.77829113e-05\n",
            "  9.36038487e-05 8.54990940e-05 5.89894516e-05 8.73565295e-05\n",
            "  6.63733663e-05 5.47157688e-05 4.55647423e-05 1.04843035e-04\n",
            "  1.08224980e-04 6.67096974e-05 2.80179975e-05 6.77838107e-05\n",
            "  5.36879779e-05 3.79190897e-05 5.68742980e-05 5.92231045e-05\n",
            "  8.10663478e-05 3.76195894e-05 6.31184594e-05 5.24720126e-05\n",
            "  7.66723315e-05 8.24893868e-05 7.12081601e-05 2.23613206e-05\n",
            "  6.44936881e-05 5.09774109e-05 5.48734788e-05 5.89740957e-05\n",
            "  7.61065094e-05 6.87889624e-05 5.93354343e-05 1.11294481e-04\n",
            "  6.92270041e-05 6.67244531e-05 3.71918031e-05 4.48453247e-05]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZcCKajyZSO8"
      },
      "source": [
        "## (c) Based on the calculated features in the previous part, which two images are more similar to each other?\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbcA5kVhSA1J",
        "outputId": "e36576cc-e218-40b2-f9d3-587274690def"
      },
      "source": [
        "# Prints the mean values of the images. It'll fill up as images are compiled.\r\n",
        "for i, f in IMG_FEATURES.items():\r\n",
        "  print(\"{} ({})\".format(i, f))"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lion (0.001000000280328095)\n",
            "Bike (0.0009999998146668077)\n",
            "Coffee (0.0010000000474974513)\n",
            "Kite (0.0010000000474974513)\n",
            "Snail (0.000999999581836164)\n",
            "Bench (0.0009999998146668077)\n",
            "Leopard (0.0010000000474974513)\n",
            "Cat (0.0009999996982514858)\n",
            "Bus (0.0009999996982514858)\n",
            "Pig (0.001000000280328095)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEPxGhiSXqoU"
      },
      "source": [
        "---\r\n",
        "Taken the mean value of every feature set to calculate how close each value is from another. These are the historical results.\r\n",
        "\r\n",
        "```\r\n",
        "Lion (0.001000000280328095)\r\n",
        "Bike (0.0009999998146668077)\r\n",
        "Coffee (0.0010000000474974513)\r\n",
        "Kite (0.0010000000474974513)\r\n",
        "Snail (0.000999999581836164)\r\n",
        "Bench (0.0009999998146668077)\r\n",
        "Leopard (0.0010000000474974513)\r\n",
        "Cat (0.0009999996982514858)\r\n",
        "Bus (0.0009999996982514858)\r\n",
        "Pig (0.001000000280328095)\r\n",
        "```\r\n",
        "Following this approach, many images share same overal similarities. Having matching images like:\r\n",
        "*   `Cat` and `Bus`.\r\n",
        "*   `Bike` and `Bench`.\r\n",
        "*   `Lion` and `Hog`.\r\n",
        "*   `Kite` with `Coffee` and `Leopard`.\r\n",
        "\r\n",
        "Making the `Snail` the only one with no shared similarities."
      ]
    }
  ]
}